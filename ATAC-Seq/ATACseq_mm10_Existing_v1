#!/bin/bash

# ATAC-seq Standarized pipeline mm10: Version -- v1.3
# Author: Edahi Gonzalez-Avalos
# Email:  edahi@lji.org
# Date:   2020.06.17
# Versions logs
# v1.3
#   Changed the temp variable since if another series of jobs whose sample names overlaps the ones in a running job, the uncompressed files in temp will be overwritten.
#   Added "exit 1" as part of the usage functions.
#   Highlighted in red improper arguments
#   Added date to versioning
#   Added Date and Version to "Usage" printout
#   Updated HELP format
#   Recorded the script name and arguments/parameters given for the log.
# v1.
#  This scrips was derived from the ATACseq_mm10_SRR_v4. The idea is to
#   (1)analyse data downloaded already [having the lanes separated] or
#   (2) linked it with the BSdownload script.
#  Adaptions extend to (and require):
#   1. Give the DIR of the current data [data should be separated by lanes]
#   2. Give the NAME of the original
#   3. Give the NAME desired for the report.

# >>> How to use the program:
#    ATACseq_mm10_Existing_v1 -s PREFIX [-n Name def:ATAC] [-d DownloadDir def:/BioScratch/edahi] [-a AnalysisDir def:/BioScratch/edahi] [-r Run created job def:no] [-q rao-exclusive queue def:no] [-h help]"
# >>> Examples:
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s CA-NFAT1-Omni_S6     -n CA-NFAT1-Omni     -d $TEMP/Giuliana/ATACseq/01.NaiveCells_EmptyCANFAT1_and_CARITNFAT1/ -a $E/Projects/Giuliana/ATAC/01.NaiveCells_EmptyCANFAT1_and_CARITNFAT1/ -q  -k
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s CA-NFAT1_S3          -n CA-NFAT1          -d $TEMP/Giuliana/ATACseq/01.NaiveCells_EmptyCANFAT1_and_CARITNFAT1/ -a $E/Projects/Giuliana/ATAC/01.NaiveCells_EmptyCANFAT1_and_CARITNFAT1/ -q  -k
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s CA-RIT-NFAT1-Omni_S7 -n CA-RIT-NFAT1-Omni -d $TEMP/Giuliana/ATACseq/01.NaiveCells_EmptyCANFAT1_and_CARITNFAT1/ -a $E/Projects/Giuliana/ATAC/01.NaiveCells_EmptyCANFAT1_and_CARITNFAT1/ -q  -k
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s CA-RIT-NFAT1_S4      -n CA-RIT-NFAT1      -d $TEMP/Giuliana/ATACseq/01.NaiveCells_EmptyCANFAT1_and_CARITNFAT1/ -a $E/Projects/Giuliana/ATAC/01.NaiveCells_EmptyCANFAT1_and_CARITNFAT1/ -q  -k
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s Empty-Omni_S5        -n Empty-Omni        -d $TEMP/Giuliana/ATACseq/01.NaiveCells_EmptyCANFAT1_and_CARITNFAT1/ -a $E/Projects/Giuliana/ATAC/01.NaiveCells_EmptyCANFAT1_and_CARITNFAT1/ -q  -k
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s Empty_S2             -n Empty             -d $TEMP/Giuliana/ATACseq/01.NaiveCells_EmptyCANFAT1_and_CARITNFAT1/ -a $E/Projects/Giuliana/ATAC/01.NaiveCells_EmptyCANFAT1_and_CARITNFAT1/ -q  -k
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s Naive_S1             -n Naive             -d $TEMP/Giuliana/ATACseq/01.NaiveCells_EmptyCANFAT1_and_CARITNFAT1/ -a $E/Projects/Giuliana/ATAC/01.NaiveCells_EmptyCANFAT1_and_CARITNFAT1/ -q  -k
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s TKO-ERT2-Cre-CD11bpositive_S4 -n TKO-ERT2-Cre-CD11bpositive -d $TEMP/Hiroshi/ATACseq/01.8_22_18_HiroshiATAC -a $E/Projects/Hiroshi/ATAC/01.8_22_18_HiroshiATAC -q -r
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s TKO-flfl-CD11bpositive_S3     -n TKO-flfl-CD11bpositive     -d $TEMP/Hiroshi/ATACseq/01.8_22_18_HiroshiATAC -a $E/Projects/Hiroshi/ATAC/01.8_22_18_HiroshiATAC -q -r
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s WT-CD11bpositive-2_S1         -n WT-CD11bpositive-2         -d $TEMP/Hiroshi/ATACseq/01.8_22_18_HiroshiATAC -a $E/Projects/Hiroshi/ATAC/01.8_22_18_HiroshiATAC -q -r
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s WT-CD11bpositive-3_S2         -n WT-CD11bpositive-3         -d $TEMP/Hiroshi/ATACseq/01.8_22_18_HiroshiATAC -a $E/Projects/Hiroshi/ATAC/01.8_22_18_HiroshiATAC -q -r
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s 11-27-CART-1_S1 -n 11-27-CART-1 -d /mnt/BioScratch/edahi/Hyungseok/ATACseq/01.11_27_18_Seo_ATAC -a /mnt/BioAdHoc/Groups/RaoLab/Edahi/Projects/Hyungseok/ATAC/01.11_27_18_Seo_ATAC -q -k
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s 11-27-CART-2_S2 -n 11-27-CART-2 -d /mnt/BioScratch/edahi/Hyungseok/ATACseq/01.11_27_18_Seo_ATAC -a /mnt/BioAdHoc/Groups/RaoLab/Edahi/Projects/Hyungseok/ATAC/01.11_27_18_Seo_ATAC -q -k
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s 11-27-CART-3_S3 -n 11-27-CART-3 -d /mnt/BioScratch/edahi/Hyungseok/ATACseq/01.11_27_18_Seo_ATAC -a /mnt/BioAdHoc/Groups/RaoLab/Edahi/Projects/Hyungseok/ATAC/01.11_27_18_Seo_ATAC -q -k
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s 11-27-CART-4_S4 -n 11-27-CART-4 -d /mnt/BioScratch/edahi/Hyungseok/ATACseq/01.11_27_18_Seo_ATAC -a /mnt/BioAdHoc/Groups/RaoLab/Edahi/Projects/Hyungseok/ATAC/01.11_27_18_Seo_ATAC -q -k
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s 11-27-DKO-5_S5 -n 11-27-DKO-5   -d /mnt/BioScratch/edahi/Hyungseok/ATACseq/01.11_27_18_Seo_ATAC -a /mnt/BioAdHoc/Groups/RaoLab/Edahi/Projects/Hyungseok/ATAC/01.11_27_18_Seo_ATAC -q -k
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s 11-27-DKO-6_S6 -n 11-27-DKO-6   -d /mnt/BioScratch/edahi/Hyungseok/ATACseq/01.11_27_18_Seo_ATAC -a /mnt/BioAdHoc/Groups/RaoLab/Edahi/Projects/Hyungseok/ATAC/01.11_27_18_Seo_ATAC -q -k
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s 11-27-DKO-7_S7 -n 11-27-DKO-7   -d /mnt/BioScratch/edahi/Hyungseok/ATACseq/01.11_27_18_Seo_ATAC -a /mnt/BioAdHoc/Groups/RaoLab/Edahi/Projects/Hyungseok/ATAC/01.11_27_18_Seo_ATAC -q -k
# $E/00.Scripts/Bash/ATACseq_mm10_Existing_v1 -s 11-27-DKO-8_S8 -n 11-27-DKO-8   -d /mnt/BioScratch/edahi/Hyungseok/ATACseq/01.11_27_18_Seo_ATAC -a /mnt/BioAdHoc/Groups/RaoLab/Edahi/Projects/Hyungseok/ATAC/01.11_27_18_Seo_ATAC -q -k

 Ver=1.3
Date=2020.06.17


usage()
{
printf "
    Version:\t %s
       Date:\t %s
\n      Usage: %s    <PARAMETERS>\n
Req:\t[ -s | --PRE       <str>   Suffix from downloaded data  Default:NONE
\n\t[ -n | --name      <str>   Name                         Default:ATAC  
\n\t[ -d | --download  <str>   DownloadPath                 Default:/mnt/beegfs 
\n\t[ -a | --analysis  <str>   AnalysisPath                 Default:/mnt/BioAdHoc/Groups/RaoLab/temp 
\n\t[ -t | --temp      <str>   TemporalPath                 Default:/mnt/BioScratch/edahi 
\n\t[ -q | --queue             set 'rao-exclusive' queue    Default:'default' 
\n\t[ -r | --run               Run created job              Default:no   
\n\t[ -k | --keep              Keep intermediate results    Default:no   
\n\t[      --rand        <#>   Temporal Folder seed Number  Default:Randomly generated
\n\t[      -help      Show this message and exit ]\n\n" $Ver $Date $0

exit 1 
}

# >>> Check if arguments given:
[[ "$1" == "" ]] &&  usage

# >>> Record parameters given: # <<< Ver v1.1
CodeLine=$0
CodeLine=${CodeLine}" "$@

# >>> Declare Variables
download=/mnt/beegfs
analysis=/mnt/BioAdHoc/Groups/RaoLab/temp
    temp=/mnt/BioScratch/edahi
 surname=
    name=ATAC
     run=0
raoqueue=default
    keep=0
    rand=$RANDOM

# >>> Assign arguments to variables
while [ "$1" != "" ]; do
    case $1 in
        -s | --PRE )            shift
                                surname=$1
                                ;;
        -n | --name )           shift
                                name=$1
                                ;;
        -d | --download )       shift
                                download=$1
                                ;;
        -a | --analysis )       shift
                                analysis=$1
                                ;;
        -t | --temp )           shift
                                temp=$1
                                ;;
             --rand   )         shift
                                rand=$1
                                ;;
        -q | --queue  )         raoqueue=rao-exclusive
                                ;;
        -k | --keep  )          keep=1
                                ;;
        -r | --run    )         run=1
                                ;;
        -h | --help )           usage
                                exit
                                ;;
        * )                     tput setaf 1 && tput bold && tput smul && printf "\n\tInvalid argument provided: %s\n\n" $1 && tput sgr0
                                grep --color=always -e "$1" <<< "${CodeLine}"
                                usage
    esac
    shift
done

# >>> Check if SRR was given:
[[ "$surname" == "" ]] && { printf "\n\tsurname is a required argument. Check --help for further assistance\n\n"; exit 1 ; } # <<< Update Ver v1.3


      Jobs=$analysis/Jobs
  softlink=$analysis/01.Data
   mapping=$analysis/02.Mapping
   TagDirs=$analysis/03.TagDirectories
FragLenEst=$analysis/04.FragmentLengthEstimates
       ssp=$analysis/05.SSP
   peakDir=$analysis/06.Peaks
   BigWigs=$analysis/07.BigWigs
    BlastR=$analysis/08.BlastResults
    FASTQC=$analysis/FASTQC
  FASTQCun=$analysis/FASTQC_UnMap
      temp=$temp/$rand

mkdir -p $Jobs $temp

cat <<EOF> $Jobs/${name}.ATACseq.mm10.Existing.v1.sh
#!/bin/bash -x
#PBS -N ${name}.ATACseq.mm10.Existing.v1
#PBS -l walltime=168:00:00
#PBS -o $Jobs/${name}.ATACseq.mm10.Existing.v1.out
#PBS -e $Jobs/${name}.ATACseq.mm10.Existing.v1.out
#PBS -j oe
#PBS -l nodes=1:ppn=4
#PBS -M edahi@lji.org
#PBS -l mem=10GB
#PBS -m ae
#PBS -q ${raoqueue}

export PATH=/share/apps/R/3.1.0/bin:/share/apps/python/python-3.4.6/bin:/share/apps/python/python-2.7.13/bin:/share/apps/perl/perl-5.18.1-threaded/bin/:/share/apps/gcc/6.3/bin:/mnt/BioApps/pigz/latest/bin:/share/apps/bin:/usr/local/maui/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/stack/bin:/share/apps/java/latest/bin:/share/apps/bowtie/bowtie2-2.1.0:/share/apps/bowtie/bowtie-1.1.2:/usr/local/cuda/bin:/share/apps/dos2unix/latest/bin:/share/apps/bedtools/bin:/share/apps/HOMER/bin
printf "PATH Used:\n\$PATH\n\n"
unset PYTHONPATH

#Variables:
    bowtie=/Bioinformatics/apps/bowtie/bowtie-1.0.0/bowtie
    fastqc=/Bioinformatics/apps/FastQC/FastQC-0.11.2/fastqc
   MarkDup=/Bioinformatics/apps/picard-tools/picard-tools-1.94/MarkDuplicates.jar
    BamCov=/home/edahi/.local/bin/bamCoverage
       Ann=/home/edahi/download/code/HOMER/bin/annotatePeaks.pl
  getPeaks=/home/edahi/download/code/HOMER/bin/findPeaks
 mMultiWig=/home/edahi/download/code/HOMER/bin/makeMultiWigHub.pl
   makeTag=/home/edahi/download/code/HOMER/bin/makeTagDirectory
 fastqdump=/home/edahi/download/code/sra/sratoolkit.2.8.2-1-ubuntu64/bin/fastq-dump
trimgalore=/home/edahi/download/code/TrimGalore/0.3.8/trim_galore
mm10genome=/mnt/BioAdHoc/Groups/RaoLab/Bioinformatics/apps/Mus_musculus/UCSC/mm10/BowtieIndex/genome
genomesize=/mnt/BioAdHoc/Groups/RaoLab/Bioinformatics/apps/Mus_musculus/UCSC/mm10/BowtieIndex/genome.fa.sizes
    Btools=/mnt/BioAdHoc/Groups/RaoLab/Edahi/00.Scripts/01.Downloaded/bedtools2/bin/bedtools
    makeBG=/mnt/BioAdHoc/Groups/RaoLab/Edahi/00.Scripts/01.Downloaded/HOMER/bin/makeUCSCfile
    Blastn=/mnt/BioAdHoc/Groups/RaoLab/Edahi/00.Scripts/01.Downloaded/ncbi-blast-2.7.1+/bin/blastn
    RunSPP=/mnt/BioAdHoc/Groups/RaoLab/Edahi/00.Scripts/01.Downloaded/phantompeakqualtools/run_spp.R
   velveth=/mnt/BioAdHoc/Groups/RaoLab/Edahi/00.Scripts/01.Downloaded/velvet_1.2.10/velveth
   velvetg=/mnt/BioAdHoc/Groups/RaoLab/Edahi/00.Scripts/01.Downloaded/velvet_1.2.10/velvetg
Fa2OneLine=/mnt/BioAdHoc/Groups/RaoLab/Edahi/00.Scripts/Bash/Fa2OneLine.sh
   BLASTDB=/mnt/BioAdHoc/Groups/RaoLab/Edahi/01.Genomes/Blast
    BLmm10=/mnt/BioAdHoc/Groups/RaoLab/Edahi/01.Genomes/Mus_musculus/UCSC/mm10/Sequence/Blacklist/mm10.blacklist.bed
      py27=/share/apps/python/python-2.7.13/bin/python
     MACS2=/share/apps/python/python-2.7.6/bin/macs2
     bg2bw=/mnt/BioAdHoc/Groups/RaoLab/Edahi/00.Scripts/Bash/bedGraph2BigWig.sh
      calc=/share/apps/UCSC/calc
   Rscript=/share/apps/R/3.1.0/bin/Rscript
       sam=/usr/bin/samtools


# From Script:
  download=$download
   surname=$surname
      name=$name
  softlink=$softlink
   mapping=$mapping
   TagDirs=$TagDirs
FragLenEst=$FragLenEst
       ssp=$ssp
   peakDir=$peakDir
   BigWigs=$BigWigs
    BlastR=$BlastR
    FASTQC=$FASTQC
  FASTQCun=$FASTQCun
      keep=$keep
      Jobs=$Jobs
      temp=$temp

# Generate Directories Framework:
mkdir -p \$softlink \$mapping/\${name} \$TagDirs \$FragLenEst \$ssp \$peakDir \$FASTQC \$FASTQCun \$BigWigs \$BlastR

# >>>>>> Merge files from same lane:
zcat \$download/\${surname}_L00*_R1*fastq.gz | gzip > \$temp/\${name}_R1.fastq.gz
zcat \$download/\${surname}_L00*_R2*fastq.gz | gzip > \$temp/\${name}_R2.fastq.gz
# cat \$download/\${surname}_L00*_R1*fastq | gzip > \$temp/\${name}_R1.fastq.gz
# cat \$download/\${surname}_L00*_R2*fastq | gzip > \$temp/\${name}_R2.fastq.gz

# >>>>>> Create Softlinks for ${name}
ln -s \$temp/\${name}_R1.fastq.gz \${softlink}/${name}_R1.fastq.gz
ln -s \$temp/\${name}_R2.fastq.gz \${softlink}/${name}_R2.fastq.gz

# >>>>>> FASTQC for downloaded files
\$fastqc \${softlink}/\${name}_R1.fastq.gz --outdir=\$FASTQC &
\$fastqc \${softlink}/\${name}_R2.fastq.gz --outdir=\$FASTQC &

# >>>>>> Mapping (1)
cd       \$mapping/\${name}
printf "Statistics for bowtie mapping of untrimmed reads \n" > \$mapping/\$name/BowtieStats.txt
nohup \$bowtie -p 4 -m 1 --best --strata -X 2000 --tryhard \\
  -S --fr --chunkmbs 2048 \$mm10genome \\
  -1  <(zcat \${softlink}/\${name}_R1.fastq.gz) \\
  -2  <(zcat \${softlink}/\${name}_R2.fastq.gz) \\
  \$mapping/\$name/\${name}_mm10.sam \\
  --un \$mapping/\$name/\${name}_unmapped.fastq &>> \$mapping/\$name/BowtieStats.txt

# >>>>>> Summary Statistics (0)(1) -- Name & Total reads
echo \${name} > \$mapping/\${name}/SummaryStats00.txt
# echo \$(grep processed \$mapping/\$name/BowtieStats.txt | cut -f2 -d: | tr -d ' ')*2|bc  > \$mapping/\${name}/SummaryStats01.txt
Treads=\$(echo \$(grep processed \$mapping/\$name/BowtieStats.txt | cut -f2 -d: | tr -d ' ' | head -n1 )*2|bc)
echo \$Treads  > \$mapping/\${name}/SummaryStats01.txt

# >>>>>> trim_galore unmapped reads
\$trimgalore --paired --nextera --length 37 \\
  --stringency 3 --three_prime_clip_R1 1 --three_prime_clip_R2 1 \\
  \$mapping/\$name/\${name}_unmapped_1.fastq \$mapping/\$name/\${name}_unmapped_2.fastq -o \$mapping/\$name

# >>>>>> FASTQC for Unmapped reads
\$fastqc \$mapping/\$name/\${name}_unmapped_1.fastq    \$mapping/\$name/\${name}_unmapped_2.fastq    --outdir=\$FASTQCun &

# >>>>>> Remap filtered-unmapped reads
printf "Statistics for bowtie mapping of trim_galore unmapped reads \n" >> \$mapping/\$name/BowtieStats.txt
nohup \$bowtie -p 4 -m 1 --best --strata -X 2500 -v 3 -e 100 --tryhard \\
  -S --fr --chunkmbs 2048 \$mm10genome \\
  -1 \$mapping/\$name/\${name}_unmapped_1_val_1.fq \\
  -2 \$mapping/\$name/\${name}_unmapped_2_val_2.fq \\
  \$mapping/\$name/\${name}_remapTrimUnmapped_mm10.sam \\
  --un \$mapping/\$name/\${name}_unmapped2.fastq &>> \$mapping/\$name/BowtieStats.txt

# >>>>>> FASTQC for Trim_Galore filtered reads
\$fastqc \$mapping/\$name/\${name}_unmapped_1_val_1.fq \$mapping/\$name/\${name}_unmapped_2_val_2.fq --outdir=\$FASTQCun &

# >>>>>> De-novo assembly from reads unmapped ont he second run: Explore what are the unmapped reads:
\$velveth \$mapping/\$name/Velvet 27 -fastq -shortPaired -separate \$mapping/\$name/\${name}_unmapped2_1.fastq \$mapping/\$name/\${name}_unmapped2_2.fastq -create_binary
nohup \$velvetg \$mapping/\$name/Velvet -cov_cutoff 17 -ins_length 300 -ins_length_sd 3 -max_branch_length 300  &>> \$mapping/\$name/Velvet/Velvetg.v1.txt

# >>>>>> Retrieve top three longest assemblies:
NODES=(\`tail -n+2 \$mapping/\$name/Velvet/stats.txt | grep -v Inf| cut -f1-2 -d\. |  awk -v OFS="\t" '\$3=\$2*\$6' | sort -k3,3n | tail -n3 | cut -f1-2 | awk '{print "NODE_"\$1"_length_"\$2"_"}'\`)
for i in \${!NODES[@]}; do
 j=\`echo \${i}+1|bc\`
 grep \${NODES[\$i]} \$mapping/\$name/Velvet/contigs.fa -A600 | awk 'BEGIN{a=0}{if(\$_ ~ /^>/){a=a+1; if(a==2){exit}} print \$_ }' > \${BlastR}/\${name}_Biggest_Contig_Length-Cov_Ratio_0\${j}.tm
done

# >>>>>> Format top three longest assemblies to OneLiners:
\$Fa2OneLine \${BlastR}/\${name}_Biggest_Contig_Length-Cov_Ratio_01.tm \${BlastR}/\${name}_Biggest_Contig_Length-Cov_Ratio_01.fa
\$Fa2OneLine \${BlastR}/\${name}_Biggest_Contig_Length-Cov_Ratio_02.tm \${BlastR}/\${name}_Biggest_Contig_Length-Cov_Ratio_02.fa
\$Fa2OneLine \${BlastR}/\${name}_Biggest_Contig_Length-Cov_Ratio_03.tm \${BlastR}/\${name}_Biggest_Contig_Length-Cov_Ratio_03.fa
rm \${BlastR}/\${name}_Biggest_Contig_Length-Cov_Ratio_0[123].tm

# >>>>>> Run Blast on each of the three longest contigs to my local databases:
\$Blastn -num_descriptions 10 -num_alignments 10  -html -query \${BlastR}/\${name}_Biggest_Contig_Length-Cov_Ratio_01.fa -db \${BLASTDB}/DownloadStuff/NT_Blasted/nt -out \${BlastR}/\${name}_Biggest_Contig_Length-Cov_Ratio_01.html
\$Blastn -num_descriptions 10 -num_alignments 10  -html -query \${BlastR}/\${name}_Biggest_Contig_Length-Cov_Ratio_02.fa -db \${BLASTDB}/DownloadStuff/NT_Blasted/nt -out \${BlastR}/\${name}_Biggest_Contig_Length-Cov_Ratio_02.html
\$Blastn -num_descriptions 10 -num_alignments 10  -html -query \${BlastR}/\${name}_Biggest_Contig_Length-Cov_Ratio_03.fa -db \${BLASTDB}/DownloadStuff/NT_Blasted/nt -out \${BlastR}/\${name}_Biggest_Contig_Length-Cov_Ratio_03.html

# In this case the warning "[bam_header_read] EOF marker is absent. The input is probably truncated."
# Should be ignored. Using samtools view on pipelines gives uncompressed bam, and these do not have the EOF marker
# >>>>>> Generating 1st step bam
\$sam view -bS \$mapping/\$name/\${name}_mm10.sam | \\
  \$sam view -h -F 4 -b - | \\
  \$sam sort - \$mapping/\$name/\${name}_mm10_onlymapped_sorted

# >>>>>> Generating 2nd step bam (remapped trimgalore)
\$sam view -bS \$mapping/\$name/\${name}_remapTrimUnmapped_mm10.sam | \\
  \$sam view -h -F 4 -b - | \\
  \$sam sort - \$mapping/\$name/\${name}_remapTrimUnmapped_mm10_onlymapped_sorted

# >>>>>> Merge both mapping results
\$sam merge \\
  \$mapping/\${name}/\${name}.mapped.sorted.merged.bam \\
  \$mapping/\$name/\${name}_mm10_onlymapped_sorted.bam \\
  \$mapping/\$name/\${name}_remapTrimUnmapped_mm10_onlymapped_sorted.bam

# >>>>>> Summary Statistics (2) -- First Mapped Reads
# grep Reported \$mapping/\$name/stats1.txt | cut -f2 -d\\   > \$mapping/\${name}/SummaryStats02.txt
\$sam view -c \$mapping/\$name/\${name}_mm10_onlymapped_sorted.bam   > \$mapping/\${name}/SummaryStats02.txt

# >>>>>> Summary Statistics (3) -- Second Mapped Reads
# grep Reported \$mapping/\$name/stats2.txt | cut -f2 -d\\   > \$mapping/\${name}/SummaryStats03.txt
\$sam view -c \$mapping/\$name/\${name}_remapTrimUnmapped_mm10_onlymapped_sorted.bam   > \$mapping/\${name}/SummaryStats03.txt

# >>>>>> Summary Statistics (4) -- Total Merged Mapped Reads
\$sam view -c \$mapping/\${name}/\${name}.mapped.sorted.merged.bam > \$mapping/\${name}/SummaryStats04.txt

# >>>>>> FragLenEst (Raw):
  \$sam view -F 0x0204 -o - \$mapping/\${name}/\${name}.mapped.sorted.merged.bam |
    awk 'BEGIN{OFS="\t"}{if (and(\$2,16) > 0) {print \$3,(\$4-1),(\$4-1+length(\$10)),"N","1000","-"} else {print \$3,(\$4-1),(\$4-1+length(\$10)),"N","1000","+"} }' |
    gzip -c > \$FragLenEst/\${name}.Raw.tagAlign.gz

# >>>>>> Run ssp [PhantomPeaks] (Raw)
\$Rscript \$RunSPP \\
    -s=-100:5:600 \\
    -c=\$FragLenEst/\${name}.Raw.tagAlign.gz -savp \\
    -out=\$ssp/\${name}.Raw.FragLenEst.tab

# >>>>>> fragmentLengthEstimate (Raw)
cat \$ssp/\${name}.Raw.FragLenEst.tab |awk '{print \$3}'|cut -d ',' -f 1 > \$FragLenEst/\${name}.Raw.FragLenEst.cat

# >>>>>> Remove chrM
\$sam view -h \$mapping/\${name}/\${name}.mapped.sorted.merged.bam | \\
  perl -lane 'print \$_ if \$F[2] ne "chrM"' | \\
  \$sam view -bS - > \$mapping/\${name}/\${name}.mapped.sorted.merged.nochrM.bam

# >>>>>> Summary Statistics (5) -- Mapped reads w/o chrM
\$sam view -c \$mapping/\${name}/\${name}.mapped.sorted.merged.nochrM.bam  > \$mapping/\${name}/SummaryStats05.txt

# >>>>>> Remove Duplicates:
java -jar \$MarkDup \
   INPUT=\$mapping/\${name}/\${name}.mapped.sorted.merged.nochrM.bam \\
   OUTPUT=\$mapping/\${name}/\${name}.mapped.sorted.merged.nochrM.rmdup.bam \\
   METRICS_FILE=\$mapping/\${name}/\${name}_PicardMetrics.txt \\
   REMOVE_DUPLICATES=true \\
   ASSUME_SORTED=true

# >>>>>> Summary Statistics (6) -- Deduplicated mapped reads w/o chrM
\$sam view -c \$mapping/\${name}/\${name}.mapped.sorted.merged.nochrM.rmdup.bam > \$mapping/\${name}/SummaryStats06.txt

# >>>>>> Whitelist:
\$Btools intersect -a \$mapping/\${name}/\${name}.mapped.sorted.merged.nochrM.rmdup.bam -b \$BLmm10 -v > \$mapping/\${name}/\${name}.whitelist.bam

# >>>>>> Summary Statistics (7) -- Raw clean mapping results
# \$sam view -c \$mapping/\${name}/\${name}.whitelist.bam  > \$mapping/\${name}/SummaryStats07.txt
Ureads=\$(\$sam view -c \$mapping/\${name}/\${name}.whitelist.bam)
echo \$Ureads > \$mapping/\${name}/SummaryStats07.txt

# >>>>>> FragLenEst (Filtered):
  \$sam view -F 0x0204 -o - \$mapping/\${name}/\${name}.whitelist.bam |
    awk 'BEGIN{OFS="\t"}{if (and(\$2,16) > 0) {print \$3,(\$4-1),(\$4-1+length(\$10)),"N","1000","-"} else {print \$3,(\$4-1),(\$4-1+length(\$10)),"N","1000","+"} }' |
    gzip -c > \$FragLenEst/\${name}.Filtered.tagAlign.gz

# >>>>>> Run ssp [PhantomPeaks] (Filtered)
\$Rscript \$RunSPP \\
    -s=-100:5:600 \\
    -c=\$FragLenEst/\${name}.Filtered.tagAlign.gz -savp \\
    -out=\$ssp/\${name}.Filtered.FragLenEst.tab

# >>>>>> fragmentLengthEstimate (Filtered)
cat \$ssp/\${name}.Filtered.FragLenEst.tab |awk '{print \$3}'|cut -d ',' -f 1 > \$FragLenEst/\${name}.Filtered.FragLenEst.cat

# >>>>>> Extract sub-nucleosomal fragments'
\$sam view -H \$mapping/\${name}/\${name}.whitelist.bam > \$mapping/\${name}/\${name}.subNuc.sam

\$sam view \$mapping/\${name}/\${name}.whitelist.bam | \\
  awk '{if(sqrt(\$9*\$9)<100){print \$0}}' >> \$mapping/\${name}/\${name}.subNuc.sam

\$sam view -S -b \$mapping/\${name}/\${name}.subNuc.sam > \$mapping/\${name}/\${name}.subNuc.bam

# >>>>>> Summary Statistics (8) -- Subnucleosomal Fragments
\$sam view -c \$mapping/\${name}/\${name}.subNuc.bam  > \$mapping/\${name}/SummaryStats08.txt

# >>>>>> Obtain Tn5 footprint (1)BamToBed (2)perlBed (3)BedToBam
\$Btools bamtobed -i \$mapping/\${name}/\${name}.whitelist.bam > \$mapping/\${name}/\${name}.whitelist.bed

/home/edahi/download/code/ATACseq/Tn5_bed9bp_full.pl \$mapping/\${name}/\${name}.whitelist.bed \$mapping/\${name}/\${name}_Tn5footprint_unsort.bed

\$Btools bedtobam -i \$mapping/\${name}/\${name}_Tn5footprint_unsort.bed -g \$genomesize | \\
  \$sam sort - \$mapping/\$name/\${name}.Tn5footprint

# >>>>>> Summary Statistics (9) -- Tn5 (9bp) Insertion sites
\$sam view -c \$mapping/\${name}/\${name}.Tn5footprint.bam  > \$mapping/\${name}/SummaryStats09.txt

# >>>>>> Summary Statistics (10) -- Usable Reads
\$calc \${Ureads}*100/\${Treads} | cut -f2 -d\= | cut -c2-6 > \$mapping/\${name}/SummaryStats10.txt

# >>>>>> Gather all summaries:
echo 'SampleName,RawReads,Mapped_1st,Mapped_2nd,TotalMapped,chrM_Filter,Duplicated_Filter,Whitelist_Filter,Subnucleosomal,Tn5_9bp_InsertionSizes,UsableReadsFromSequenced' >  \$mapping/\${name}/Colnames.MappingStats.csv
paste -d, \$mapping/\${name}/SummaryStats0[0-9].txt  \$mapping/\${name}/SummaryStats10.txt  >  \$mapping/\${name}/MappingStats.csv

# >>>>>>Indexes of all files (1)Clean Mapping Results (2)SubNucleosomal (3)Tn5Footprint
\$sam index \$mapping/\${name}/\${name}.whitelist.bam
\$sam index \$mapping/\${name}/\${name}.subNuc.bam
\$sam index \$mapping/\${name}/\${name}.Tn5footprint.bam

# >>>>>> Calculate fragment length distributions
\$py27 /home/edahi/download/code/ATACseq/Fragment_length_density_plot.py \$mapping/\${name}/\${name}.whitelist.bam \$name \$FragLenEst/\${name}_fragmentLengths

# >>>>>> Generate Tag Directories
mkdir -p  \$TagDirs/\${name}_whitelist \$TagDirs/\${name}_subNuc \$TagDirs/\${name}_Tn5
\$makeTag \$TagDirs/\${name}_whitelist -keepAll -illuminaPE \$mapping/\${name}/\${name}.whitelist.bam    > \$TagDirs/\${name}_whitelist/maketagdir.txt
\$makeTag \$TagDirs/\${name}_subNuc    -keepAll -illuminaPE \$mapping/\${name}/\${name}.subNuc.bam       > \$TagDirs/\${name}_subNuc/maketagdir.txt
\$makeTag \$TagDirs/\${name}_Tn5       -keepAll -illuminaPE \$mapping/\${name}/\${name}.Tn5footprint.bam > \$TagDirs/\${name}_Tn5/maketagdir.txt

# >>>>>> Generate BigWig files
\$makeBG   \$TagDirs/\${name}_whitelist -o auto -fsize 1e20
\$makeBG   \$TagDirs/\${name}_subNuc    -o auto -fsize 1e20
\$makeBG   \$TagDirs/\${name}_Tn5       -o auto -fsize 1e20

zcat \$TagDirs/\${name}_whitelist/\${name}_whitelist.ucsc.bedGraph.gz | tail -n+2 | sort -k1,1 -k2,2n > \$TagDirs/\${name}_whitelist/\${name}_whitelist.ucsc.bedGraph
zcat \$TagDirs/\${name}_subNuc/\${name}_subNuc.ucsc.bedGraph.gz       | tail -n+2 | sort -k1,1 -k2,2n > \$TagDirs/\${name}_subNuc/\${name}_subNuc.ucsc.bedGraph
zcat \$TagDirs/\${name}_Tn5/\${name}_Tn5.ucsc.bedGraph.gz             | tail -n+2 | sort -k1,1 -k2,2n > \$TagDirs/\${name}_Tn5/\${name}_Tn5.ucsc.bedGraph

\$bg2bw \$TagDirs/\${name}_whitelist/\${name}_whitelist.ucsc.bedGraph \$BigWigs/\${name}.whitelist.bw mm10
\$bg2bw \$TagDirs/\${name}_subNuc/\${name}_subNuc.ucsc.bedGraph       \$BigWigs/\${name}.subNuc.bw    mm10
\$bg2bw \$TagDirs/\${name}_Tn5/\${name}_Tn5.ucsc.bedGraph             \$BigWigs/\${name}.Tn5.bw       mm10

# \$BamCov --bam \$mapping/\${name}/\${name}.Tn5footprint.bam --numberOfProcessors 4 --binSize 1  --normalizeUsing RPKM --smoothLength 1  --ignoreDuplicates -o \$BigWigs/\${name}.Tn5_9bp.bw  --maxFragmentLength 10 &
# \$BamCov --bam \$mapping/\${name}/\${name}.subNuc.bam       --numberOfProcessors 4 --binSize 10 --normalizeUsing RPKM --smoothLength 30 --ignoreDuplicates -o \$BigWigs/\${name}.subNuc.bw &
# \$BamCov --bam \$mapping/\${name}/\${name}.whitelist.bam    --numberOfProcessors 4 --binSize 10 --normalizeUsing RPKM --smoothLength 30 --ignoreDuplicates -o \$BigWigs/\${name}.whitelist.bw

# >>> Add BigWigs to tracks file:
echo track type=bigWig name=\${name}.whitelist description=\${name}.whitelist visibility=2 autoScale=off maxHeightPixels=40 viewLimits=0:200 color=10,10,10 graphType=bar bigDataUrl=http://informaticsdata.liai.org/NGS_analyses/ad_hoc/\${BigWigs/\\/mnt\/BioAdHoc\\//}/\${name}.whitelist.bw >> \${BigWigs}/ATAC_Tracks_Whitelist.txt
echo track type=bigWig name=\${name}.subNuc    description=\${name}.subNuc    visibility=2 autoScale=off maxHeightPixels=40 viewLimits=0:200 color=0,0,255  graphType=bar bigDataUrl=http://informaticsdata.liai.org/NGS_analyses/ad_hoc/\${BigWigs/\\/mnt\/BioAdHoc\\//}/\${name}.subNuc.bw    >> \${BigWigs}/ATAC_Tracks_subNuc.txt
echo track type=bigWig name=\${name}.Tn5       description=\${name}.Tn5       visibility=2 autoScale=off maxHeightPixels=40 viewLimits=0:200 color=0,255,0  graphType=bar bigDataUrl=http://informaticsdata.liai.org/NGS_analyses/ad_hoc/\${BigWigs/\\/mnt\/BioAdHoc\\//}/\${name}.Tn5_9bp.bw   >> \${BigWigs}/ATAC_Tracks_Tn5_9bp.txt

# >>>>>> Call Peaks
\$getPeaks \$TagDirs/\${name}_whitelist -style dnase -center -nfr -L 10 -localSize 3000 -o \$peakDir/HOMER.\${name}.whitelist.peaks.txt
\$getPeaks \$TagDirs/\${name}_subNuc    -style dnase -center -nfr -L 10 -localSize 3000 -o \$peakDir/HOMER.\${name}.subNuc.peaks.txt
\$getPeaks \$TagDirs/\${name}_Tn5       -style dnase -center -nfr -L 10 -localSize 3000 -o \$peakDir/HOMER.\${name}.Tn5.peaks.txt

\$MACS2 callpeak -t \$mapping/\${name}/\${name}.whitelist.bam    -f BAMPE  -n \$peakDir/MACS2.\${name}.whitelist -g mm -q 0.0001  --keep-dup all --nomodel --call-summits
\$MACS2 callpeak -t \$mapping/\${name}/\${name}.subNuc.bam       -f BAMPE  -n \$peakDir/MACS2.\${name}.subNuc    -g mm -q 0.0001  --keep-dup all --nomodel --call-summits
\$MACS2 callpeak -t \$mapping/\${name}/\${name}.Tn5footprint.bam -f BAM    -n \$peakDir/MACS2.\${name}.Tn5       -g mm -q 0.0001  --keep-dup all --nomodel --call-summits

# >>>>>> Extend 200 the peak summits:
awk -v OFS="\t" '{if(\$2 > 101){\$2 = \$2-100} else {\$2=1}; \$3=\$3+100; print \$_}' \$peakDir/MACS2.\${name}.whitelist_summits.bed > \$peakDir/MACS2.\${name}.whitelist_summits.200bp.bed
awk -v OFS="\t" '{if(\$2 > 101){\$2 = \$2-100} else {\$2=1}; \$3=\$3+100; print \$_}' \$peakDir/MACS2.\${name}.subNuc_summits.bed    > \$peakDir/MACS2.\${name}.subNuc_summits.200bp.bed
awk -v OFS="\t" '{if(\$2 > 101){\$2 = \$2-100} else {\$2=1}; \$3=\$3+100; print \$_}' \$peakDir/MACS2.\${name}.Tn5_summits.bed       > \$peakDir/MACS2.\${name}.Tn5_summits.200bp.bed

# >>>>>> Remove Intermediate Files (if selected):
if [ "\$keep" = "0" ]; then
 rm \$mapping/\$name/\${name}*.sam
 rm \$mapping/\$name/\${name}_unmapped*q
 rm \$mapping/\${name}/\${name}*mapped*.bam
 rm \$FragLenEst/\${name}.*.tagAlign.gz
 rm \$mapping/\${name}/\${name}*.bed
 rm \$mapping/\${name}/SummaryStats0[0-9].txt
 rm \$mapping/\${name}/gmon.out
fi

EOF

# >>> If selected, Run job
if [ "$run" = "1" ]; then
 echo "Running Job"
 qsub $Jobs/${name}.ATACseq.mm10.Existing.v1.sh
fi

